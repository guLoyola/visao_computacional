{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba2eba93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-12 20:19:38.924484: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-12 20:19:38.954395: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-12 20:19:39.677046: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "import shutil\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f520942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU disponível: 1 GPU(s) encontrada(s)\n",
      "   JIT compilation: Desabilitado (para evitar erros)\n",
      "TensorFlow version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Reduz logs do TensorFlow\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/lib/cuda'  # Configuração XLA\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.config.optimizer.set_jit(False)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"✅ GPU disponível: {len(gpus)} GPU(s) encontrada(s)\")\n",
    "        print(f\"   JIT compilation: Desabilitado (para evitar erros)\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"⚠️ Erro ao configurar GPU: {e}\")\n",
    "else:\n",
    "    print(\"⚠️ Nenhuma GPU encontrada. Usando CPU.\")\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae1fe7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a1eb703",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "path2 = ROOT_DIR + '/data/muhammad0subhan/fruit-and-vegetable-disease-healthy-vs-rotten/versions/1/Fruit And Vegetable Diseases Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad0cfcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = os.listdir(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a75563e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Carrot__Healthy',\n",
       " 'Potato__Healthy',\n",
       " 'Tomato__Healthy',\n",
       " 'Carrot__Rotten',\n",
       " 'Tomato__Rotten',\n",
       " 'Potato__Rotten']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1378e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique fruits found: 3\n",
      "['carrot', 'potato', 'tomato']\n"
     ]
    }
   ],
   "source": [
    "def extract_fruit_name(name):\n",
    "    name = name.lower()\n",
    "    name = re.sub(r'^(fresh|rotten)', '', name)\n",
    "    name = re.sub(r'(s)$','',name)\n",
    "    name = re.sub(r'(__healthy|__rotten)$', '', name)\n",
    "    return name.strip()\n",
    "cleaned_fruits = set([extract_fruit_name(fruit) for fruit in full])\n",
    "print(\"Unique fruits found:\", len(cleaned_fruits))\n",
    "print(sorted(cleaned_fruits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c59d42ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'carrot': 0, 'potato': 0, 'tomato': 0}\n"
     ]
    }
   ],
   "source": [
    "freshfruit_dict = {fruit: 0 for fruit in cleaned_fruits}\n",
    "rottenfruit_dict = {fruit: 0 for fruit in cleaned_fruits}\n",
    "print(freshfruit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "786f0c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carrot__Rotten  :  580\n",
      "Tomato__Rotten  :  596\n",
      "Potato__Rotten  :  585\n"
     ]
    }
   ],
   "source": [
    "for i in full :\n",
    "    if re.sub(r'(__Rotten)$','',i).lower() in cleaned_fruits:\n",
    "        rottenfruit_dict[re.sub(r'(__Rotten)$','',i).lower()] += len(os.listdir(os.path.join(path2,i)))\n",
    "        print(i,' : ',len(os.listdir(os.path.join(path2,i))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f43edb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carrot__Healthy  :  620\n",
      "Potato__Healthy  :  615\n",
      "Tomato__Healthy  :  604\n"
     ]
    }
   ],
   "source": [
    "for i in full :\n",
    "    if re.sub(r'(__Healthy)$','',i).lower() in cleaned_fruits:\n",
    "        freshfruit_dict[re.sub(r'(__Healthy)$','',i).lower()] += len(os.listdir(os.path.join(path2,i)))\n",
    "        print(i,' : ',len(os.listdir(os.path.join(path2,i))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8333f91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'carrot': 620, 'potato': 615, 'tomato': 604}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freshfruit_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a565b011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'carrot': 580, 'potato': 585, 'tomato': 596}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rottenfruit_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda7f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_augmented_images_limited_per_image(src_folder, dst_folder, num_images, image_size=(224, 224), per_image_limit=20):\n",
    "    \"\"\"\n",
    "    Generate augmented images, limiting to `per_image_limit` per source image.\n",
    "\n",
    "    Args:\n",
    "        src_folder (str): Path to source folder with original images.\n",
    "        dst_folder (str): Destination folder for augmented images.\n",
    "        num_images (int): Total augmented images to generate.\n",
    "        image_size (tuple): Resize all images to this size. Default (224, 224).\n",
    "        per_image_limit (int): Max images to generate per source image. Default 20.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(dst_folder):\n",
    "        os.makedirs(dst_folder)\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=25,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    image_files = [f for f in os.listdir(\n",
    "        src_folder) if f.lower().endswith(('jpg', 'jpeg', 'png'))]\n",
    "    if not image_files:\n",
    "        print(\"❌ No valid images found in source folder.\")\n",
    "        return\n",
    "\n",
    "    total_generated = 0\n",
    "\n",
    "    for image_file in image_files:\n",
    "        if total_generated >= num_images:\n",
    "            break\n",
    "\n",
    "        img_path = os.path.join(src_folder, image_file)\n",
    "        img = load_img(img_path, target_size=image_size)\n",
    "        x = img_to_array(img)\n",
    "        x = x.reshape((1,) + x.shape)\n",
    "\n",
    "        images_to_generate = min(per_image_limit, num_images - total_generated)\n",
    "        count = 0\n",
    "\n",
    "        for batch in datagen.flow(x, batch_size=1, save_to_dir=dst_folder,\n",
    "                                  save_prefix='aug', save_format='jpg'):\n",
    "            count += 1\n",
    "            total_generated += 1\n",
    "            if count >= images_to_generate or total_generated >= num_images:\n",
    "                break\n",
    "\n",
    "    print(f\"✅ Generated {total_generated} augmented images in '{dst_folder}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a07a3a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_dataset(src_dir, dst_dir):\n",
    "    \"\"\"\n",
    "    Copy the entire folder structure and files from `src_dir` to `dst_dir`.\n",
    "\n",
    "    Args:\n",
    "        src_dir (str): Path to the original dataset.\n",
    "        dst_dir (str): Path to the new directory where the dataset will be copied.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(dst_dir):\n",
    "        os.makedirs(dst_dir)\n",
    "\n",
    "    for folder_name in os.listdir(src_dir):\n",
    "        src_folder_path = os.path.join(src_dir, folder_name)\n",
    "        dst_folder_path = os.path.join(dst_dir, folder_name)\n",
    "\n",
    "        if os.path.isdir(src_folder_path):\n",
    "            shutil.copytree(src_folder_path, dst_folder_path,\n",
    "                            dirs_exist_ok=True)\n",
    "            print(f\"✅ Copied: {folder_name}\")\n",
    "        else:\n",
    "            print(f\"❌ Skipped (not a folder): {folder_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc7802",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_dir = ROOT_DIR + '/data/working'\n",
    "copy_dataset(path2, dst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9052cdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carrot__Healthy  :  620\n",
      "✅ Generated 380 augmented images in '/home/dev/repos/diogo/visao_computacional/data/working/Carrot__Healthy'\n",
      "Potato__Healthy  :  615\n",
      "✅ Generated 385 augmented images in '/home/dev/repos/diogo/visao_computacional/data/working/Potato__Healthy'\n",
      "Tomato__Healthy  :  604\n",
      "✅ Generated 396 augmented images in '/home/dev/repos/diogo/visao_computacional/data/working/Tomato__Healthy'\n",
      "Carrot__Rotten  :  580\n",
      "✅ Generated 420 augmented images in '/home/dev/repos/diogo/visao_computacional/data/working/Carrot__Rotten'\n",
      "Tomato__Rotten  :  596\n",
      "✅ Generated 404 augmented images in '/home/dev/repos/diogo/visao_computacional/data/working/Tomato__Rotten'\n",
      "Potato__Rotten  :  585\n",
      "✅ Generated 415 augmented images in '/home/dev/repos/diogo/visao_computacional/data/working/Potato__Rotten'\n"
     ]
    }
   ],
   "source": [
    "for i in full:\n",
    "    if len(os.listdir(os.path.join(dst_dir, i))) < 1000:\n",
    "        print(i, ' : ', len(os.listdir(os.path.join(path2, i))))\n",
    "        generate_augmented_images_limited_per_image(os.path.join(dst_dir, i), os.path.join(\n",
    "            dst_dir, i), 1000 - len(os.listdir(os.path.join(path2, i))), image_size=(224, 224), per_image_limit=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1b94664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:02<00:11,  2.33s/it]/home/dev/repos/diogo/visao_computacional/.venv/lib/python3.11/site-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.15s/it]\n"
     ]
    }
   ],
   "source": [
    "def ensure_image_size(img_path, target_size=(224, 224)):\n",
    "    try:\n",
    "        with Image.open(img_path) as img:\n",
    "            img = img.convert('RGB')  # Convert from RGBA to RGB\n",
    "            if img.size != target_size:\n",
    "                img = img.resize(target_size)\n",
    "            img.save(img_path)  # Overwrite\n",
    "    except Exception as e:\n",
    "        print(f\"Error resizing {img_path}: {e}\")\n",
    "\n",
    "\n",
    "def split_and_resize_dataset(src_dir, dst_dir, target_size=(224, 224), train_count=850, val_count=100):\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "    for class_name in tqdm(os.listdir(src_dir)):\n",
    "        class_path = os.path.join(src_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        images = [f for f in os.listdir(\n",
    "            class_path) if f.lower().endswith(('jpg', 'jpeg', 'png'))]\n",
    "        random.shuffle(images)\n",
    "\n",
    "        train_images = images[:train_count]\n",
    "        val_images = images[train_count:train_count+val_count]\n",
    "\n",
    "        for phase, image_set in zip(['train', 'val'], [train_images, val_images]):\n",
    "            phase_class_path = os.path.join(dst_dir, phase, class_name)\n",
    "            os.makedirs(phase_class_path, exist_ok=True)\n",
    "\n",
    "            for img_name in image_set:\n",
    "                src_img_path = os.path.join(class_path, img_name)\n",
    "                dst_img_path = os.path.join(phase_class_path, img_name)\n",
    "\n",
    "                ensure_image_size(src_img_path, target_size)\n",
    "                shutil.copy(src_img_path, dst_img_path)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "split_and_resize_dataset(\n",
    "    src_dir=dst_dir,\n",
    "    dst_dir=dst_dir,\n",
    "    target_size=(224, 224)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff4413cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Carrot__Healthy',\n",
       " 'Potato__Healthy',\n",
       " 'Tomato__Healthy',\n",
       " 'Carrot__Rotten',\n",
       " 'Tomato__Rotten',\n",
       " 'Potato__Rotten']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(dst_dir + '/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e5521fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5100 images belonging to 6 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = dst_dir + \"/train\"\n",
    "val_dir = dst_dir + \"/val\"\n",
    "\n",
    "img_size = 224\n",
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_data = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d1b0b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1760311214.152707  166123 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4028 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-10-12 20:20:14.286146: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:14.289707: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:14.293008: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:14.296920: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:14.300407: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:14.303725: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:14.306855: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:14.310008: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:14.312925: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:14.315934: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:14.318923: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:14.321857: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:14.324644: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "base_model.trainable = True # Freeze base layers\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "predictions = Dense(train_data.num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    "    run_eagerly=True  # This can help with some execution issues\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86b86b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/repos/diogo/visao_computacional/.venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "2025-10-12 20:20:18.419080: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002\n",
      "2025-10-12 20:20:18.637600: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:18.639078: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:18.640390: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:18.641829: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:18.643239: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:18.644673: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:18.646198: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:18.647601: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:18.761003: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:19.035306: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:19.036727: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:19.038170: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:19.039700: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:19.041417: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:19.043579: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:19.046459: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:19.049259: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:19.051871: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:19.303905: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:20.127891: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:20.129371: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:20.131199: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:20.132572: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:20.133989: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:20.135336: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:20.136855: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:20.144949: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:20.274482: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:20.309799: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:20.609403: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:20.611266: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:20.612724: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:20.614231: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:20.617248: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:20.620413: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:20.623348: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:20.626337: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:20.799515: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:20.801185: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:20.803281: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:20.805941: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:20.809030: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/319\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:47\u001b[0m 3s/step - accuracy: 0.2500 - loss: 1.9092"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-12 20:20:20.811920: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:20.814891: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-12 20:20:20.817972: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:188] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 463ms/step - accuracy: 0.8992 - loss: 0.3033 - val_accuracy: 0.8067 - val_loss: 0.6195\n",
      "Epoch 2/6\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 461ms/step - accuracy: 0.9716 - loss: 0.0881 - val_accuracy: 0.9150 - val_loss: 0.2548\n",
      "Epoch 3/6\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 461ms/step - accuracy: 0.9794 - loss: 0.0646 - val_accuracy: 0.9433 - val_loss: 0.1974\n",
      "Epoch 4/6\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 462ms/step - accuracy: 0.9859 - loss: 0.0416 - val_accuracy: 0.9583 - val_loss: 0.1493\n",
      "Epoch 5/6\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 464ms/step - accuracy: 0.9867 - loss: 0.0389 - val_accuracy: 0.9767 - val_loss: 0.0945\n",
      "Epoch 6/6\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 462ms/step - accuracy: 0.9920 - loss: 0.0249 - val_accuracy: 0.9617 - val_loss: 0.1396\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=6  # increase if needed\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visao-computacional",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
